{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername : 0 - 20\n",
      "Filename : youinna1.wav\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "cffi library 'C:\\Users\\ImChanjoo\\anaconda3\\Library\\bin\\sndfile.dll' has no function, constant or global variable named 'sf_wchar_open'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-30b5971f7801>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[1;31m#print(\"mfcc :\",mfcc.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mload_wave_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-30b5971f7801>\u001b[0m in \u001b[0;36mload_wave_generator\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[1;32mglobal\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;31m#전역변수를 사용하겠다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Filename :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.wav 파일이 아니면 continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mmfcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    625\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    626\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_unicode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m                     \u001b[0mopenfunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_wchar_open\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: cffi library 'C:\\Users\\ImChanjoo\\anaconda3\\Library\\bin\\sndfile.dll' has no function, constant or global variable named 'sf_wchar_open'"
     ]
    }
   ],
   "source": [
    "##### 화자인식 일반 머신러닝 코드 #####\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pyaudio #마이크를 사용하기 위한 라이브러리\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression#텐서플로우로 바꿀예정\n",
    "import os\n",
    "##### 변수 설정 부분 #####\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100 #비트레이트 설정\n",
    "CHUNK = int(RATE / 10) # 버퍼 사이즈 1초당 44100비트레이트 이므로 100ms단위\n",
    "RECORD_SECONDS = 1 #녹음할 시간 설정\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "DATA_PATH = \"./data/\"\n",
    "train_data=[]#train_date 저장할 공강\n",
    "train_label=[]#train_label 저장할 \n",
    "test_data=[]#train_date 저장할 공강\n",
    "test_label=[]#train_label 저장할 \n",
    "##########################\n",
    "\n",
    "def load_wave_generator(path): \n",
    "       \n",
    "    batch_waves = []\n",
    "    labels = []\n",
    "    # input_width=CHUNK*6 # wow, big!!\n",
    "    folders = os.listdir(path)\n",
    "    #while True:\n",
    "       # print(\"loaded batch of %d files\" % len(files))\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(path):continue #폴더가 아니면 continue                   \n",
    "        files = os.listdir(path+\"/\"+folder)        \n",
    "        print(\"Foldername :\",folder,\"-\",len(files))#폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "        for wav in files:\n",
    "            if not wav.endswith(\".wav\"):continue\n",
    "            else:\n",
    "                global train_data,train_label#전역변수를 사용하겠다.\n",
    "                print(\"Filename :\",wav)#.wav 파일이 아니면 continue\n",
    "                y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "                if(len(train_data)==0):\n",
    "                    train_data = mfcc\n",
    "                    train_label = np.full(len(mfcc), int(folder))\n",
    "                else:\n",
    "                    train_data = np.concatenate((train_data, mfcc), axis = 0)\n",
    "                    train_label = np.concatenate((train_label, np.full(len(mfcc),  int(folder))), axis = 0)\n",
    "                    #print(\"mfcc :\",mfcc.shape)\n",
    "                \n",
    "load_wave_generator(DATA_PATH)\n",
    "\n",
    "\n",
    "######## 음성 데이터를 녹음 해 저장하는 부분 ########\n",
    "\n",
    "p = pyaudio.PyAudio() # 오디오 객체 생성\n",
    "\n",
    "stream = p.open(format=FORMAT, # 16비트 포맷\n",
    "                channels=CHANNELS, #  모노로 마이크 열기\n",
    "                rate=RATE, #비트레이트\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK) # CHUNK만큼 버퍼가 쌓인다.\n",
    "\n",
    "print(\"Start to record the audio.\")\n",
    "\n",
    "frames = [] # 음성 데이터를 채우는 공간\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)): \n",
    "    #지정한  100ms를 몇번 호출할 것인지 10 * 5 = 50  100ms 버퍼 50번채움 = 5초\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Recording is finished.\")\n",
    "\n",
    "stream.stop_stream() # 스트림닫기\n",
    "stream.close() # 스트림 종료\n",
    "p.terminate() # 오디오객체 종료\n",
    "\n",
    "# WAVE_OUTPUT_FILENAME의 파일을 열고 데이터를 쓴다.\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb') \n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "spf = wave.open(WAVE_OUTPUT_FILENAME,'r')\n",
    "\n",
    "signal = spf.readframes(-1)\n",
    "signal = np.fromstring(signal, dtype=np.int16)\n",
    "\n",
    "#시간 흐름에 따른 그래프를 그리기 위한 부분\n",
    "Time = np.linspace(0,len(signal)/RATE, num=len(signal)) \n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Voice Signal Wave...')\n",
    "#plt.plot(signal) // 음성 데이터의 그래프\n",
    "plt.plot(Time, signal)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "######## 음성 데이터를 읽어와 학습 시키는 부분 ########\n",
    "\n",
    "print(\"train_data.shape :\", train_data.shape, type(train_data))\n",
    "print(\"train_label.shape :\", train_label.shape, type(train_label))\n",
    "#print(mfcc[0])\n",
    "#print(train_label)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data,train_label)\n",
    "\n",
    "y, sr = librosa.load(\"./test_유인나1.wav\")\n",
    "#y, sr = librosa.load(\"./baecheolsu15.wav\")\n",
    "plt.figure(figsize=(14,5))\n",
    "librosa.display.waveplot(y, sr)\n",
    "#y, sr = librosa.load(WAVE_OUTPUT_FILENAME)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "y_test_estimated = clf.predict(mfcc)\n",
    "print(y_test_estimated)\n",
    "test_label = np.full(len(mfcc), 0)\n",
    "print(test_label)\n",
    "'''\n",
    "0 유인나\n",
    "1 배철수\n",
    "2 이재은\n",
    "3 최일구\n",
    "4 문재인 대통령\n",
    "'''\n",
    "# 정답률 구하기 \n",
    "ac_score = metrics.accuracy_score(y_test_estimated, test_label)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(pd.value_counts(pd.Series(y_test_estimated)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21개의 .wav존재! ./data/train/4/문재인대통령21.wav\n",
      "Start to record the audio.\n",
      "Recording is finished.\n"
     ]
    }
   ],
   "source": [
    "##### 단순히 목소리 녹음을 위한 부분 #####\n",
    "\n",
    "import pyaudio #마이크를 사용하기 위한 라이브러리\n",
    "import wave #.wav 파일을 저장하기 위한 라이브러리\n",
    "import os\n",
    "######## 음성 데이터를 녹음 해 저장하는 부분 ########\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100 #비트레이트 설정\n",
    "CHUNK = int(RATE / 10) # 버퍼 사이즈 1초당 44100비트레이트 이므로 100ms단위\n",
    "RECORD_SECONDS = 5 #녹음할 시간 설정\n",
    "#WAVE_OUTPUT_FILENAME = \"./data/train/1/baecheolsu15.wav\"\n",
    "WAVE_OUTPUT_FILENAME = \"./data/train/4/\"\n",
    "FILE_NAME = \"문재인대통령\"\n",
    "\n",
    "files = os.listdir(WAVE_OUTPUT_FILENAME)\n",
    "wave_count = 1;\n",
    "     #폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "for wav in files: \n",
    "    if not wav.endswith(\".wav\"):continue\n",
    "    else: wave_count = wave_count+1\n",
    "\n",
    "\n",
    "WAVE_OUTPUT_FILENAME = WAVE_OUTPUT_FILENAME+FILE_NAME+str(wave_count)+\".wav\"\n",
    "print(str(wave_count)+\"개의 .wav존재!\",WAVE_OUTPUT_FILENAME)\n",
    "p = pyaudio.PyAudio() # 오디오 객체 생성\n",
    "\n",
    "stream = p.open(format=FORMAT, # 16비트 포맷\n",
    "                channels=CHANNELS, #  모노로 마이크 열기\n",
    "                rate=RATE, #비트레이트\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK) # CHUNK만큼 버퍼가 쌓인다.\n",
    "\n",
    "print(\"Start to record the audio.\")\n",
    "\n",
    "frames = [] # 음성 데이터를 채우는 공간\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)): \n",
    "    #지정한  100ms를 몇번 호출할 것인지 10 * 5 = 50  100ms 버퍼 50번채움 = 5초\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Recording is finished.\")\n",
    "\n",
    "stream.stop_stream() # 스트림닫기\n",
    "stream.close() # 스트림 종료\n",
    "p.terminate() # 오디오객체 종료\n",
    "\n",
    "wf = wave.open( WAVE_OUTPUT_FILENAME, 'wb') \n",
    "# WAVE_OUTPUT_FILENAME의 파일을 열고 데이터를 쓴다.\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername : 0 - 20\n",
      "Filename : youinna1.wav\n",
      "Filename : youinna10.wav\n",
      "Filename : youinna11.wav\n",
      "Filename : youinna12.wav\n",
      "Filename : youinna13.wav\n",
      "Filename : youinna14.wav\n",
      "Filename : youinna15.wav\n",
      "Filename : youinna2.wav\n",
      "Filename : youinna3.wav\n",
      "Filename : youinna4.wav\n",
      "Filename : youinna5.wav\n",
      "Filename : youinna6.wav\n",
      "Filename : youinna7.wav\n",
      "Filename : youinna8.wav\n",
      "Filename : youinna9.wav\n",
      "Filename : 유인나16.wav\n",
      "Filename : 유인나17.wav\n",
      "Filename : 유인나18.wav\n",
      "Filename : 유인나19.wav\n",
      "Filename : 유인나20.wav\n",
      "Foldername : 1 - 20\n",
      "Filename : baecheolsu1.wav\n",
      "Filename : baecheolsu10.wav\n",
      "Filename : baecheolsu11.wav\n",
      "Filename : baecheolsu12.wav\n",
      "Filename : baecheolsu13.wav\n",
      "Filename : baecheolsu14.wav\n",
      "Filename : baecheolsu2.wav\n",
      "Filename : baecheolsu3.wav\n",
      "Filename : baecheolsu4.wav\n",
      "Filename : baecheolsu5.wav\n",
      "Filename : baecheolsu6.wav\n",
      "Filename : baecheolsu7.wav\n",
      "Filename : baecheolsu8.wav\n",
      "Filename : baecheolsu9.wav\n",
      "Filename : 배철수15.wav\n",
      "Filename : 배철수16.wav\n",
      "Filename : 배철수17.wav\n",
      "Filename : 배철수18.wav\n",
      "Filename : 배철수19.wav\n",
      "Filename : 배철수20.wav\n",
      "Foldername : 2 - 20\n",
      "Filename : 이재은1.wav\n",
      "Filename : 이재은10.wav\n",
      "Filename : 이재은11.wav\n",
      "Filename : 이재은12.wav\n",
      "Filename : 이재은13.wav\n",
      "Filename : 이재은14.wav\n",
      "Filename : 이재은15.wav\n",
      "Filename : 이재은16.wav\n",
      "Filename : 이재은17.wav\n",
      "Filename : 이재은18.wav\n",
      "Filename : 이재은19.wav\n",
      "Filename : 이재은2.wav\n",
      "Filename : 이재은20.wav\n",
      "Filename : 이재은3.wav\n",
      "Filename : 이재은4.wav\n",
      "Filename : 이재은5.wav\n",
      "Filename : 이재은6.wav\n",
      "Filename : 이재은7.wav\n",
      "Filename : 이재은8.wav\n",
      "Filename : 이재은9.wav\n",
      "Foldername : 3 - 20\n",
      "Filename : 최일구1.wav\n",
      "Filename : 최일구10.wav\n",
      "Filename : 최일구11.wav\n",
      "Filename : 최일구12.wav\n",
      "Filename : 최일구13.wav\n",
      "Filename : 최일구14.wav\n",
      "Filename : 최일구15.wav\n",
      "Filename : 최일구16.wav\n",
      "Filename : 최일구17.wav\n",
      "Filename : 최일구18.wav\n",
      "Filename : 최일구19.wav\n",
      "Filename : 최일구2.wav\n",
      "Filename : 최일구20.wav\n",
      "Filename : 최일구3.wav\n",
      "Filename : 최일구4.wav\n",
      "Filename : 최일구5.wav\n",
      "Filename : 최일구6.wav\n",
      "Filename : 최일구7.wav\n",
      "Filename : 최일구8.wav\n",
      "Filename : 최일구9.wav\n",
      "Foldername : 4 - 20\n",
      "Filename : 문재인대통령1.wav\n",
      "Filename : 문재인대통령10.wav\n",
      "Filename : 문재인대통령11.wav\n",
      "Filename : 문재인대통령12.wav\n",
      "Filename : 문재인대통령13.wav\n",
      "Filename : 문재인대통령14.wav\n",
      "Filename : 문재인대통령15.wav\n",
      "Filename : 문재인대통령16.wav\n",
      "Filename : 문재인대통령17.wav\n",
      "Filename : 문재인대통령18.wav\n",
      "Filename : 문재인대통령19.wav\n",
      "Filename : 문재인대통령2.wav\n",
      "Filename : 문재인대통령20.wav\n",
      "Filename : 문재인대통령3.wav\n",
      "Filename : 문재인대통령4.wav\n",
      "Filename : 문재인대통령5.wav\n",
      "Filename : 문재인대통령6.wav\n",
      "Filename : 문재인대통령7.wav\n",
      "Filename : 문재인대통령8.wav\n",
      "Filename : 문재인대통령9.wav\n",
      "X_data : (50200, 13)\n",
      "Y_label : (50200, 5)\n",
      "X_train : (37650, 13)\n",
      "X_test : (12550, 13)\n",
      "Y_train : (37650, 5)\n",
      "Y_test : (12550, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################이건 함수 테스트 하는부분\n",
    "import librosa\n",
    "import pyaudio #마이크를 사용하기 위한 라이브러리\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression#텐서플로우로 바꿀예정\n",
    "import os\n",
    "##### 변수 설정 부분 #####\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100 #비트레이트 설정\n",
    "CHUNK = int(RATE / 10) # 버퍼 사이즈 1초당 44100비트레이트 이므로 100ms단위\n",
    "RECORD_SECONDS = 5 #녹음할 시간 설정\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "DATA_PATH = \"./data/\"\n",
    "X_train = []#train_data 저장할 공간\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "def load_wave_generator(path): \n",
    "       \n",
    "    batch_waves = []\n",
    "    labels = []\n",
    "    X_data = []\n",
    "    Y_label = []\n",
    "    idx = 0\n",
    "    global X_train, X_test, Y_train, Y_test\n",
    "    folders = os.listdir(path)\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(path):continue #폴더가 아니면 continue                   \n",
    "        files = os.listdir(path+\"/\"+folder)        \n",
    "        print(\"Foldername :\",folder,\"-\",len(files))\n",
    "        #폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "        for wav in files:\n",
    "            if not wav.endswith(\".wav\"):continue\n",
    "            else:               \n",
    "                print(\"Filename :\",wav)#.wav 파일이 아니면 continue\n",
    "                y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "                X_data.extend(mfcc)\n",
    "                label = [0 for i in range(len(folders))]\n",
    "                label[idx] = 1\n",
    "                for i in range(len(mfcc)):\n",
    "                    Y_label.append(label)       \n",
    "        idx = idx+1\n",
    "    #end loop\n",
    "    print(\"X_data :\",np.shape(X_data))\n",
    "    print(\"Y_label :\",np.shape(Y_label))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_label)\n",
    "    \n",
    "    #3d to 2d\n",
    "#     nsamples, nx, ny = np.shape(X_train)\n",
    "#     X_train = np.reshape(X_train,(nsamples,nx*ny))\n",
    "#     nsamples, nx, ny = np.shape(X_test)\n",
    "#     X_test = np.reshape(X_test,(nsamples,nx*ny))    \n",
    "    \n",
    "#     Y_train = np.argmax(Y_train, axis=1)###one-hot을 합침\n",
    "#     Y_test = np.argmax(Y_test, axis=1)###one-hot을 합침\n",
    "    xy = (X_train, X_test, Y_train, Y_test)\n",
    "    np.save(\"./data.npy\",xy)\n",
    "    #print(X_data)\n",
    "    #print(Y_label)\n",
    "                \n",
    "load_wave_generator(DATA_PATH)\n",
    "\n",
    "#t = np.array(X_train);\n",
    "#print(\"!!!!!!!!\",t,t.shape,X_train)\n",
    "print(\"X_train :\",np.shape(X_train))\n",
    "print(\"X_test :\",np.shape(X_test))\n",
    "print(\"Y_train :\",np.shape(Y_train))\n",
    "print(\"Y_test :\",np.shape(Y_test))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, np.argmax(Y_train, axis=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 0.6353784860557768\n",
      "0    2750\n",
      "2    2746\n",
      "3    2402\n",
      "4    2351\n",
      "1    2301\n",
      "dtype: int64\n",
      "(502, 13)\n",
      "정답률 = 0.8007968127490039\n",
      "0    402\n",
      "4     60\n",
      "1     29\n",
      "3      6\n",
      "2      5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "############### 일반 머신러닝에서 전체적인 정확도 측정 ###########\n",
    "\n",
    "y_test_estimated = clf.predict(X_test)\n",
    "\n",
    "# 정답률 구하기 \n",
    "ac_score = metrics.accuracy_score(np.argmax(Y_test, axis=1), y_test_estimated)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(pd.value_counts(pd.Series(y_test_estimated)))\n",
    "\n",
    "\n",
    "#y, sr = librosa.load(\"./youinna16.wav\")\n",
    "#y, sr = librosa.load(\"./baecheolsu15.wav\")\n",
    "y, sr = librosa.load(\"./test_유인나1.wav\")\n",
    "\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "print(mfcc.shape)\n",
    "\n",
    "y_test_estimated = clf.predict(mfcc)\n",
    "\n",
    "# 정답률 구하기 \n",
    "ac_score = metrics.accuracy_score(np.full(len(mfcc),0), y_test_estimated)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(pd.value_counts(pd.Series(y_test_estimated)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername : 0 - 20 파일\n",
      "Foldername : 1 - 20 파일\n",
      "Foldername : 2 - 20 파일\n",
      "Foldername : 3 - 20 파일\n",
      "Foldername : 4 - 20 파일\n",
      "X_data : (50200, 13)\n",
      "Y_label : (50200, 5)\n",
      "5 개의 클래스!!\n",
      "X_train : (37650, 13)\n",
      "Y_train : (37650, 5)\n",
      "X_test : (12550, 13)\n",
      "Y_test : (12550, 5)\n"
     ]
    }
   ],
   "source": [
    "#######################Tensorflow 코드 시작부분\n",
    "import librosa\n",
    "import pyaudio #마이크를 사용하기 위한 라이브러리\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "##### 변수 설정 부분 #####\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100 #비트레이트 설정\n",
    "CHUNK = int(RATE / 10) # 버퍼 사이즈 1초당 44100비트레이트 이므로 100ms단위\n",
    "RECORD_SECONDS = 5 #녹음할 시간 설정\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "DATA_PATH = \"./data/\"\n",
    "X_train = []#train_data 저장할 공간\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "tf_classes = 0\n",
    "def load_wave_generator(path): \n",
    "       \n",
    "    batch_waves = []\n",
    "    labels = []\n",
    "    X_data = []\n",
    "    Y_label = []    \n",
    "    global X_train, X_test, Y_train, Y_test, tf_classes\n",
    "    \n",
    "    folders = os.listdir(path)\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(path):continue #폴더가 아니면 continue                   \n",
    "        files = os.listdir(path+\"/\"+folder)        \n",
    "        print(\"Foldername :\",folder,\"-\",len(files),\"파일\")\n",
    "        #폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "        for wav in files:\n",
    "            if not wav.endswith(\".wav\"):continue\n",
    "            else:               \n",
    "                #print(\"Filename :\",wav)#.wav 파일이 아니면 continue\n",
    "                y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "              \n",
    "                X_data.extend(mfcc)\n",
    "               # print(len(mfcc))\n",
    "                \n",
    "                label = [0 for i in range(len(folders))]\n",
    "                label[tf_classes] = 1\n",
    "                \n",
    "                for i in range(len(mfcc)):\n",
    "                    Y_label.append(label)\n",
    "                #print(Y_label)\n",
    "        tf_classes = tf_classes+1\n",
    "    #end loop\n",
    "    print(\"X_data :\",np.shape(X_data))\n",
    "    print(\"Y_label :\",np.shape(Y_label))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.array(X_data), np.array(Y_label))\n",
    "\n",
    "    xy = (X_train, X_test, Y_train, Y_test)\n",
    "    np.save(\"./data.npy\",xy)\n",
    "\n",
    "load_wave_generator(DATA_PATH)\n",
    "\n",
    "#t = np.array(X_train);\n",
    "#print(\"!!!!!!!!\",t,t.shape,X_train)\n",
    "print(tf_classes,\"개의 클래스!!\")\n",
    "print(\"X_train :\",np.shape(X_train))\n",
    "print(\"Y_train :\",np.shape(Y_train))\n",
    "print(\"X_test :\",np.shape(X_test))\n",
    "print(\"Y_test :\",np.shape(Y_test))\n",
    "####################\n",
    "#clf = LogisticRegression()\n",
    "#clf.fit(X_train, Y_train)\n",
    "####################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 cost = 1.768258393\n",
      "Epoch: 0001 cost = 1.685209215\n",
      "Epoch: 0002 cost = 1.653463840\n",
      "Epoch: 0003 cost = 1.642655313\n",
      "Epoch: 0004 cost = 1.632559121\n",
      "Epoch: 0005 cost = 1.626507938\n",
      "Epoch: 0006 cost = 1.623970628\n",
      "Epoch: 0007 cost = 1.617627859\n",
      "Epoch: 0008 cost = 1.613074362\n",
      "Epoch: 0009 cost = 1.612866640\n",
      "Epoch: 0010 cost = 1.608623147\n",
      "Epoch: 0011 cost = 1.601703107\n",
      "Epoch: 0012 cost = 1.594674408\n",
      "Epoch: 0013 cost = 1.582768321\n",
      "Epoch: 0014 cost = 1.571101725\n",
      "Epoch: 0015 cost = 1.552175045\n",
      "Epoch: 0016 cost = 1.527016640\n",
      "Epoch: 0017 cost = 1.501027048\n",
      "Epoch: 0018 cost = 1.473427057\n",
      "Epoch: 0019 cost = 1.450169683\n",
      "Epoch: 0020 cost = 1.420166731\n",
      "Epoch: 0021 cost = 1.400464892\n",
      "Epoch: 0022 cost = 1.370797276\n",
      "Epoch: 0023 cost = 1.350872397\n",
      "Epoch: 0024 cost = 1.322831690\n",
      "Epoch: 0025 cost = 1.306846738\n",
      "Epoch: 0026 cost = 1.283440530\n",
      "Epoch: 0027 cost = 1.265479803\n",
      "Epoch: 0028 cost = 1.244811952\n",
      "Epoch: 0029 cost = 1.229327917\n",
      "Epoch: 0030 cost = 1.214277267\n",
      "Epoch: 0031 cost = 1.200754046\n",
      "Epoch: 0032 cost = 1.179933667\n",
      "Epoch: 0033 cost = 1.171465278\n",
      "Epoch: 0034 cost = 1.157186031\n",
      "Epoch: 0035 cost = 1.148637772\n",
      "Epoch: 0036 cost = 1.129880607\n",
      "Epoch: 0037 cost = 1.119567573\n",
      "Epoch: 0038 cost = 1.103682816\n",
      "Epoch: 0039 cost = 1.101206362\n",
      "Epoch: 0040 cost = 1.088949621\n",
      "Epoch: 0041 cost = 1.078730583\n",
      "Epoch: 0042 cost = 1.065548003\n",
      "Epoch: 0043 cost = 1.061150849\n",
      "Epoch: 0044 cost = 1.051678896\n",
      "Epoch: 0045 cost = 1.040553510\n",
      "Epoch: 0046 cost = 1.035540819\n",
      "Epoch: 0047 cost = 1.025181532\n",
      "Epoch: 0048 cost = 1.020949662\n",
      "Epoch: 0049 cost = 1.013657928\n",
      "Epoch: 0050 cost = 1.009527087\n",
      "Epoch: 0051 cost = 1.001051426\n",
      "Epoch: 0052 cost = 0.995533168\n",
      "Epoch: 0053 cost = 0.988470912\n",
      "Epoch: 0054 cost = 0.984737813\n",
      "Epoch: 0055 cost = 0.974493951\n",
      "Epoch: 0056 cost = 0.972250104\n",
      "Epoch: 0057 cost = 0.968054265\n",
      "Epoch: 0058 cost = 0.963661879\n",
      "Epoch: 0059 cost = 0.958159506\n",
      "Epoch: 0060 cost = 0.951948404\n",
      "Epoch: 0061 cost = 0.949526519\n",
      "Epoch: 0062 cost = 0.943110317\n",
      "Epoch: 0063 cost = 0.937596738\n",
      "Epoch: 0064 cost = 0.928734422\n",
      "Epoch: 0065 cost = 0.931762576\n",
      "Epoch: 0066 cost = 0.926227391\n",
      "Epoch: 0067 cost = 0.920588315\n",
      "Epoch: 0068 cost = 0.918895811\n",
      "Epoch: 0069 cost = 0.916721165\n",
      "Epoch: 0070 cost = 0.909283400\n",
      "Epoch: 0071 cost = 0.906341761\n",
      "Epoch: 0072 cost = 0.893812150\n",
      "Epoch: 0073 cost = 0.896080941\n",
      "Epoch: 0074 cost = 0.893776089\n",
      "Epoch: 0075 cost = 0.885982066\n",
      "Epoch: 0076 cost = 0.885417610\n",
      "Epoch: 0077 cost = 0.880378515\n",
      "Epoch: 0078 cost = 0.874407470\n",
      "Epoch: 0079 cost = 0.870458603\n",
      "Epoch: 0080 cost = 0.866873652\n",
      "Epoch: 0081 cost = 0.863877654\n",
      "Epoch: 0082 cost = 0.854783624\n",
      "Epoch: 0083 cost = 0.847053885\n",
      "Epoch: 0084 cost = 0.846763730\n",
      "Epoch: 0085 cost = 0.842363864\n",
      "Epoch: 0086 cost = 0.835846007\n",
      "Epoch: 0087 cost = 0.834317952\n",
      "Epoch: 0088 cost = 0.826066405\n",
      "Epoch: 0089 cost = 0.823091626\n",
      "Epoch: 0090 cost = 0.821037769\n",
      "Epoch: 0091 cost = 0.811819047\n",
      "Epoch: 0092 cost = 0.807224303\n",
      "Epoch: 0093 cost = 0.801750571\n",
      "Epoch: 0094 cost = 0.797068417\n",
      "Epoch: 0095 cost = 0.794919580\n",
      "Epoch: 0096 cost = 0.792424530\n",
      "Epoch: 0097 cost = 0.787290722\n",
      "Epoch: 0098 cost = 0.783482373\n",
      "Epoch: 0099 cost = 0.777337164\n",
      "Accuracy:  0.7505179\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "##################  화자인식 NN 버전 ##################\n",
    "X_train, X_test, Y_train, Y_test = np.load(\"./data.npy\")\n",
    "X_train = X_train.astype(\"float\")\n",
    "X_test = X_test.astype(\"float\")\n",
    "\n",
    "tf.reset_default_graph() \n",
    "tf.set_random_seed(777)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "sd = 1 / np.sqrt(13) # standard deviation 표준편차(표본표준편차라 1/root(n))\n",
    "\n",
    "#mfcc의 기본은 20\n",
    "# 20ms일 때216은 각 mfcc feature의 열이 216\n",
    "X = tf.placeholder(tf.float32, [None, 13])\n",
    "# \n",
    "Y = tf.placeholder(tf.float32, [None, tf_classes])\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([216, 200]))\n",
    "# b = tf.Variable(tf.random_normal([200]))\n",
    "\n",
    "#1차 히든레이어\n",
    "W1 = tf.get_variable(\"w1\",\n",
    "    #tf.random_normal([216, 180], mean=0, stddev=sd),\n",
    "        shape=[13, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256], mean=0, stddev=sd), name=\"b1\")\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1) # 1차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "# 2차 히든 레이어\n",
    "W2 = tf.get_variable(\"w2\",\n",
    "    #tf.random_normal([180, 150], mean=0, stddev=sd),\n",
    "         shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256], mean=0, stddev=sd), name=\"b2\")\n",
    "L2 = tf.nn.tanh(tf.matmul(L1, W2) + b2) # 2차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "# 3차 히든 레이어\n",
    "W3 = tf.get_variable(\"w3\",\n",
    "    #tf.random_normal([150, 100], mean=0, stddev=sd),\n",
    "            shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([256], mean=0, stddev=sd), name=\"b3\")\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3) # 3차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "# 4차 히든 레이어\n",
    "W4 = tf.get_variable(\"w4\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[256, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b4\")\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4) # 4차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "# 5차 히든 레이어\n",
    "W5 = tf.get_variable(\"w5\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[128, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b5\")\n",
    "L5 = tf.nn.relu(tf.matmul(L4, W5) + b5) # 5차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L5 = tf.nn.dropout(L5, keep_prob = keep_prob)\n",
    "\n",
    "# 6차 히든 레이어\n",
    "W6 = tf.get_variable(\"w6\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[128, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b6\")\n",
    "L6 = tf.nn.relu(tf.matmul(L5, W6) + b6) # 6차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L6 = tf.nn.dropout(L6, keep_prob = keep_prob)\n",
    "\n",
    "# 7차 히든 레이어\n",
    "W7 = tf.get_variable(\"w7\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[128, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b7\")\n",
    "L7 = tf.nn.relu(tf.matmul(L6, W7) + b7) # 7차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L7 = tf.nn.dropout(L7, keep_prob = keep_prob)\n",
    "\n",
    "# 최종 레이어\n",
    "W8 = tf.get_variable(\"w8\", \n",
    "    #tf.random_normal([50, tf_classes], mean=0, stddev=sd),\n",
    "            shape=[128, tf_classes],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b8 = tf.Variable(tf.random_normal([tf_classes], mean=0, stddev=sd), name=\"b8\")\n",
    "hypothesis = tf.matmul(L7, W8) + b8\n",
    "\n",
    "\n",
    "\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "\n",
    "batch_size=1\n",
    "x_len = len(X_train)\n",
    "#짝수\n",
    "if(x_len%2==0):\n",
    "    batch_size = 2\n",
    "elif(x_len%3==0):\n",
    "    batch_size = 3\n",
    "elif(x_len%4==0):\n",
    "    batch_size = 4\n",
    "else:\n",
    "    batch_size = 1\n",
    "\n",
    "split_X = np.split(X_train,batch_size)\n",
    "split_Y = np.split(Y_train,batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(batch_size):\n",
    "        batch_xs = split_X[i]\n",
    "        batch_ys = split_Y[i]\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / batch_size\n",
    "        #if(epoch%10==0):\n",
    "    print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 cost = 0.433902234\n",
      "Epoch: 0001 cost = 0.431479573\n",
      "Epoch: 0002 cost = 0.433456764\n",
      "Epoch: 0003 cost = 0.431102067\n",
      "Epoch: 0004 cost = 0.434130162\n",
      "Epoch: 0005 cost = 0.436263233\n",
      "Epoch: 0006 cost = 0.433312997\n",
      "Epoch: 0007 cost = 0.428633839\n",
      "Epoch: 0008 cost = 0.428357914\n",
      "Epoch: 0009 cost = 0.431287184\n",
      "Epoch: 0010 cost = 0.428853288\n",
      "Epoch: 0011 cost = 0.432199582\n",
      "Epoch: 0012 cost = 0.431376532\n",
      "Epoch: 0013 cost = 0.430958167\n",
      "Epoch: 0014 cost = 0.430181354\n",
      "Epoch: 0015 cost = 0.428414404\n",
      "Epoch: 0016 cost = 0.431304425\n",
      "Epoch: 0017 cost = 0.428372502\n",
      "Epoch: 0018 cost = 0.429700345\n",
      "Epoch: 0019 cost = 0.426049367\n",
      "Epoch: 0020 cost = 0.431025878\n",
      "Epoch: 0021 cost = 0.425560474\n",
      "Epoch: 0022 cost = 0.428268731\n",
      "Epoch: 0023 cost = 0.427496314\n",
      "Epoch: 0024 cost = 0.426692918\n",
      "Epoch: 0025 cost = 0.431261614\n",
      "Epoch: 0026 cost = 0.428164929\n",
      "Epoch: 0027 cost = 0.426149562\n",
      "Epoch: 0028 cost = 0.427241907\n",
      "Epoch: 0029 cost = 0.424440548\n",
      "Epoch: 0030 cost = 0.425014555\n",
      "Epoch: 0031 cost = 0.426298842\n",
      "Epoch: 0032 cost = 0.424697950\n",
      "Epoch: 0033 cost = 0.432408810\n",
      "Epoch: 0034 cost = 0.429748788\n",
      "Epoch: 0035 cost = 0.424295649\n",
      "Epoch: 0036 cost = 0.425727785\n",
      "Epoch: 0037 cost = 0.424384832\n",
      "Epoch: 0038 cost = 0.421998382\n",
      "Epoch: 0039 cost = 0.421833783\n",
      "Epoch: 0040 cost = 0.423988611\n",
      "Epoch: 0041 cost = 0.422183856\n",
      "Epoch: 0042 cost = 0.427709907\n",
      "Epoch: 0043 cost = 0.423435077\n",
      "Epoch: 0044 cost = 0.422316909\n",
      "Epoch: 0045 cost = 0.422897503\n",
      "Epoch: 0046 cost = 0.424059987\n",
      "Epoch: 0047 cost = 0.423869357\n",
      "Epoch: 0048 cost = 0.419292942\n",
      "Epoch: 0049 cost = 0.422291055\n",
      "Epoch: 0050 cost = 0.418099970\n",
      "Epoch: 0051 cost = 0.418897897\n",
      "Epoch: 0052 cost = 0.421981722\n",
      "Epoch: 0053 cost = 0.420122623\n",
      "Epoch: 0054 cost = 0.419019267\n",
      "Epoch: 0055 cost = 0.417752519\n",
      "Epoch: 0056 cost = 0.417026833\n",
      "Epoch: 0057 cost = 0.421011463\n",
      "Epoch: 0058 cost = 0.416879430\n",
      "Epoch: 0059 cost = 0.418491349\n",
      "Epoch: 0060 cost = 0.413627714\n",
      "Epoch: 0061 cost = 0.418905586\n",
      "Epoch: 0062 cost = 0.420893788\n",
      "Epoch: 0063 cost = 0.417725310\n",
      "Epoch: 0064 cost = 0.416141197\n",
      "Epoch: 0065 cost = 0.422601208\n",
      "Epoch: 0066 cost = 0.415263921\n",
      "Epoch: 0067 cost = 0.414047047\n",
      "Epoch: 0068 cost = 0.411169901\n",
      "Epoch: 0069 cost = 0.415347144\n",
      "Epoch: 0070 cost = 0.416715369\n",
      "Epoch: 0071 cost = 0.415724218\n",
      "Epoch: 0072 cost = 0.413205907\n",
      "Epoch: 0073 cost = 0.414286777\n",
      "Epoch: 0074 cost = 0.417515129\n",
      "Epoch: 0075 cost = 0.413838193\n",
      "Epoch: 0076 cost = 0.406672046\n",
      "Epoch: 0077 cost = 0.414380252\n",
      "Epoch: 0078 cost = 0.409244984\n",
      "Epoch: 0079 cost = 0.410085127\n",
      "Epoch: 0080 cost = 0.410260558\n",
      "Epoch: 0081 cost = 0.408219934\n",
      "Epoch: 0082 cost = 0.408373520\n",
      "Epoch: 0083 cost = 0.412397876\n",
      "Epoch: 0084 cost = 0.408391535\n",
      "Epoch: 0085 cost = 0.410602748\n",
      "Epoch: 0086 cost = 0.410913154\n",
      "Epoch: 0087 cost = 0.412660941\n",
      "Epoch: 0088 cost = 0.411385298\n",
      "Epoch: 0089 cost = 0.411987484\n",
      "Epoch: 0090 cost = 0.409864917\n",
      "Epoch: 0091 cost = 0.411050737\n",
      "Epoch: 0092 cost = 0.407668844\n",
      "Epoch: 0093 cost = 0.409624293\n",
      "Epoch: 0094 cost = 0.411008745\n",
      "Epoch: 0095 cost = 0.409316033\n",
      "Epoch: 0096 cost = 0.406920210\n",
      "Epoch: 0097 cost = 0.406415075\n",
      "Epoch: 0098 cost = 0.409248039\n",
      "Epoch: 0099 cost = 0.409810767\n",
      "Accuracy:  0.9721116\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "#학습만 반복 코스트 보며 설정\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(batch_size):\n",
    "        batch_xs = split_X[i]\n",
    "        batch_ys = split_Y[i]\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / batch_size\n",
    "        #if(epoch%10==0):\n",
    "    print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n",
    "\n",
    "print('Learning Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_voice_model2'"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './my_voice_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 13)\n",
      "(502, 5)\n",
      "predict\n",
      "2    488\n",
      "4      6\n",
      "3      6\n",
      "1      2\n",
      "dtype: int64\n",
      "Accuracy:  0.9721116\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(\"./test_이재은.wav\")\n",
    "\n",
    "X_test = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "'''\n",
    "0 유인나\n",
    "1 배철수\n",
    "2 이재은\n",
    "3 최일구\n",
    "4 문재인 대통령\n",
    "'''\n",
    "label = [0 for i in range(5)]#class가 3개이니까 y_test만드는 과정\n",
    "label[2] = 1\n",
    "Y_test = []\n",
    "for i in range(len(X_test)):\n",
    "    Y_test.append(label)\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(Y_test))\n",
    "\n",
    "\n",
    "#correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n",
    "#print(\"Label :\",sess.run(tf.argmax(Y_test,1)))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"predict\")\n",
    "print(pd.value_counts(pd.Series(sess.run(tf.argmax(hypothesis, 1),\n",
    "                                    feed_dict={X: X_test, keep_prob:1}))))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
